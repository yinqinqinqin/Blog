---
title: 作品集
data: 2024-7-3 19:52:54
updated: 2024-7-3
tags: 
    - TA
    - Creation
categories: Creation
description: This is my 作品集
cover: https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202403191721875.png
---

# 作品集

{% note blue %}

前言：这本作品集是我学习与实践的成果，它记录了我的专业技能与创作思路。每一份作品都代表了我对专业的理解和对品质的追求。希望通过这些精选的作品，能够让您更直观地了解我的实力与潜力。期待有机会为您的团队贡献我的力量。

{% endnote %}

带宽速度不高，加载速度会有一定的影响，经过测试输出的内容还是比较稳定的。

## Logo效果

{% tabs 视频%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/LOGO.mp4 %}
{% endvideos %}

<!-- endtab -->

<!-- tab 细节部分-->

{% tabs 体积光 %}
<!-- tab 体积光和SSR反射-->
{% gallery %}
![2024-4-18 3_07_06](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725272.png)

![image-20240418032736469](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725273.png)

![image-20240418032753632](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725274.png)

{% endgallery %}
<!-- endtab -->

<!-- tab 代码分析-->

**体积光**

处理：

a. 初始化射线、步长、当前位置、衰减率和颜色。

b. 进入一个循环，在循环中：

- 使用噪声纹理和当前位置计算出一个噪声值，这个噪声值乘以密度来控制体积光的分布。
- 更新衰减率，模拟光线在介质中传播时的衰减。
- 如果衰减率低于某个阈值，则提前退出循环，因为此时的光线已经非常微弱。
- 更新当前位置，沿着射线方向前进一个步长。
- 累加颜色值，这里使用了一个简单的基于高度的雾色模型。
  c. 将累加的颜色值乘以曝光度，并设置颜色的alpha值为1.0，表示不透明。
  d. 返回最终的颜色值。

**SSR镜面反射**

1. 计算反射路径
   - 使用相机到点的向量`V`和水面法线计算出反射方向。
   - 根据这个反射方向和预设的SSR长度，确定反射光线在世界空间中的终点和远点。
2. 转换到屏幕空间
   - 把世界空间的反射路径起点、终点、远点转换为裁剪空间，再进一步转换为屏幕空间坐标。
3. 快速检查远点
   - 如果远点在屏幕范围内，检查其深度，如果深度合适，则直接采样该点的颜色作为反射颜色。
4. 线性追踪
   - 从屏幕空间的起点开始，沿着反射路径逐步前进。
   - 在每一步，检查当前点的屏幕空间坐标是否在屏幕范围内，以及当前点的深度是否比之前记录的深度更近。
   - 如果找到一个有效的交点（即深度比之前记录的近），则记录这个交点的屏幕空间坐标。
5. 采样反射颜色
   - 如果有有效的交点，根据交点的屏幕空间坐标采样颜色，并乘以一个基于视角和法线夹角的衰减因子。
   - 如果没有有效的交点，但远点检查成功，则使用远点的颜色。
   - 如果都没有成功，则反射颜色可能保持为初始化的零值或预设的默认值。

**LOGO模型**

1. 设计Logo模型
   - 初步构思Logo形状与风格
   - 完成Logo的初步设计
2. 为Logo增加视觉效果
   - 添加扰动效果，赋予Logo动态感
   - 融入反射效果，提升Logo的光泽与立体感
   - 点缀星星效果，使Logo更加璀璨
   - 添加**虚拟光效果**，模拟点光源增加一个光照效果，跟随小球运动实现实时渲染
3. 让Logo动起来
   - 添加运动效果，使Logo更生动
4. 增加环境元素
   - 在Logo周围添加飘动的小球和旋转的圆环，营造活泼、动感的氛围

<!-- endtab -->

{% endtabs %}



<!-- endtab -->

<!-- tab 部分源代码展示-->

**Logo模型的ASE代码**![image-20240418034245510](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725275.png)

**体积光部分代码**

```
//AABB
 bool intersectAABB(float3 rayOrigin, float3 rayDir, float3 boxMin,
                               float3 boxMax, out float2 tNearFar)
            {
                float3 tMin = (boxMin - rayOrigin) / rayDir;
                float3 tMax = (boxMax - rayOrigin) / rayDir;
                float3 t1 = min(tMin, tMax);
                float3 t2 = max(tMin, tMax);
                float tNear = max(max(t1.x, t1.y), t1.z);
                float tFar = min(min(t2.x, t2.y), t2.z);
                tNearFar = float2(tNear, tFar);

                return tFar > tNear;
            }


//光线步进
UNITY_LOOP
for (float k = 0; k < vlSamples; k++)
{
    float f = saturate((k + rand()) / vlSamples);
    float3 p = lerp(startPos, endPos, f);

    //射线与平面求交
    float distance;
    // float3 lightDir = normalize(LightPos - p);
    // iPlane(p,L,float4(0,-1,0,0.5),distance);
    intersectPlane(float3(0, -1, 0), float3(0, 0.5, 0), p, L, distance);
    float3 hitPos = p + L * distance;

    //白色体积光
    float3 caustic = GetCaustic(hitPos.xz);
    //*hsv2rgb(float3((p.y+_RainbowOffset + dot(L,-rayDir))*_RainbowScale+0.5,_RainbowIntensity,1));//*spectral_zucconi6(p.y+0.5);
    //彩色体积光
    float noise = tex2D(_Noise, hitPos.xz).r;
    noise = lerp(1, 1.3, noise);
    float3 causticColorful = 5 * GetCaustic(hitPos.xz) *
        hsv2rgb(float3(
        (p.y + _RainbowOffset + dot(L, -rayDir) * 0.1) * _RainbowScale * noise + 0.5,
        _RainbowIntensity, 1)); 
    float rinbowMask = tex2D(_RainbowMask, hitPos.xz * 3);
    caustic = lerp(caustic, causticColorful*1.5, rinbowMask) * 1.5;
    // caustic = (causticColorful) * 1.5;

    vlLight += caustic * add;
}

//体积光 核心算法 =======================================================

float height = input.posOS.y + 0.5;
float noise = tex2D(_Noise, input.posOS.xz).r;

vlLight = vlLight * smoothstep(0.2, 1.1 + noise, height) * 20;
vlLight = vlLight * multipleOctaves(height, cosTheta);

float3 color = lerp(_Color1, _Color2, height) * 0.5 + vlLight; 

float alpha = exp(-rayMaxDistance * _Density);
```

**SSR镜面部分代码**

```
    //远处的反射 RayMarch 无法Hit到
    float fade = pow(1-dot(normalize(V),waterNormal),1 );//fresnel
    // 最远端在相机视口内
    UNITY_BRANCH if((far_ScreenPixelNdcZ).y<1)
    {

        float farDepth =  GetDepth(far_ScreenPixelNdcZ.xy);
        farDepth = LinearEyeDepth(farDepth);
        UNITY_BRANCH if(abs(farDepth)<SSRLength)
        {
            // SSRColor =  GetSceneColor(far_ScreenPixelNdcZ.xy)*fade*float4(1,0,0,0);
            SSRColor = GetSceneColor(far_ScreenPixelNdcZ.xy)*fade;
        }
        else
        {
            SSRColor.w = 1;
        }
    }
    UNITY_LOOP
    for (int n=1;n<MaxLingearStep;n++)
    {
        Ray += Step;
        //如果测试点跑到 视口外面去了，那么停止for循环
        UNITY_BRANCH if(Ray.z<0 || Ray.z>1 || Ray.x<0 || Ray.x>1 || Ray.y<0 || Ray.y>1)
        {
            break;
        }
        float Depth = GetDepth(Ray.xy);
        //  上一次深度<Depth<这一次深度
        // if(Depth + _PerPixelCompareBias >Ray.z && Ray.z <Depth +_PerPixelDepthBias )
        if(Ray.z < Depth  && Depth < LastDepth)
        {
            isHit = true;
            hitUV = Ray.xy;
            break;
        }
        LastDepth =Ray.z;
    }
    if(isHit)
    {
        SSRColor =  GetSceneColor(hitUV)*fade;
    }
```

<!-- endtab -->

{% endtabs %}

## 视差卡片

{% tabs 视差卡片%}

<!-- tab 渲染效果-->

{% tabs 视差卡片%}

<!-- tab 多巴胺女孩-->

{% videos, 2 %}

{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/parallax4.mp4 %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/Parallax1.mp4 %}

{% endvideos %}

<!-- endtab -->

<!-- tab 模特橱窗-->

{% videos, 2 %}

{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/parallax3.mp4 %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/parallax2.mp4 %}

{% endvideos %}

<!-- endtab -->

<!-- tab 模板测试3D效果-->

{% videos %}

{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/TemplentTest.mp4 %}

{% endvideos %}

<!-- endtab -->

<!-- tab 深度测试滤镜效果-->

{% gallery %}

![2024-4-16 10_17_29](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725276.png)

{% endgallery %}

<!-- endtab -->

{% endtabs %}

<!-- endtab -->

<!-- tab 细节部分-->

## **视差效果算法**

![](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725277.png)

### 计算视角与法线的夹角余弦值

通过计算`ViewTS`与z轴的点积（dot product）来得到夹角的余弦值。

**1.计算视差长度**

使用`Depth`除以夹角的余弦值来计算视差效果的长度。

**2.计算偏移纹理坐标**

根据`ViewTS`和视差长度来计算出偏移后的纹理坐标。

**3.采样纹理**

使用偏移后的纹理坐标从`_Map`中采样颜色。

### **橱窗效果**

**1.生成深度图**

使用Stable Diffusion技术，开始制作深度图。

选择一种方法生成深度图：

使用具有浮雕效果的lora技术：通过lora处理原始2D图像，强调图像中的轮廓和细节，从而生成初始的深度信息。

或者，利用controlNet插件：这个插件可以分析图像中的空间关系和物体层次，生成更为精确的深度图。

**2.调整深度图**

打开Photoshop或其他图像处理软件。

导入生成的深度图。

调整深度图的明度，以确保深度信息的准确性和视觉效果的协调性。

**3.应用视差效果** 

将调整后的深度图应用于原始2D图像上，使用视差算法根据深度信息对图像进行分层处理。

调整视差效果的参数，以达到理想的3D橱窗效果。这些参数可能包括视差强度、分层数量等。

4.**最终调整与输出**

对生成的3D橱窗效果进行最后的调整和优化，确保整体视觉效果的自然和协调。

导出最终的3D橱窗效果图像，准备用于展示或分享。

## **贴图制作**

多巴胺女孩和模特均由Sdable Diffusion制作，背景则是ps制作

主要步骤：

加载stable diffusion环境，选择大模型（猴人3D重制 V10.safetensors）

参数配置

![](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725279.png)

![](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725278.png)

再添加想要的提示词就能得到想要的图片啦

### 高光和流光效果

高光效果可通过Blinn-Phong模型中的dot(N,H)实现，或通过光晕函数模拟，结合全局虚拟点光源和HSV色彩模型，呈现绚丽色彩。而流光效果则可采用Luminance函数或遮罩贴图来精准定位流光的动感部位。

## 模板测试

**1.设置蒙版的属性**

```
ZWrite off//需要关闭深度写入，否则在渲染透明物体的时候会出错，透明物体会修改深度缓冲区

//其中_ID是指可以通过蒙版显示的模型ID
Stencil{
      Ref[_ID]//在模板缓存区中存储一个蒙版测试的ID
      Comp always//设置这个ID的属性为可通过
      Pass replace 
}  
```

**2.给模型设置ID**

```
Stencil {
      Ref [_ID]
      Comp equal//模板测试将检查模板缓冲区中当前像素位置的值是否等于 Ref 设定的参考值（_ID）。如果相等，则测试通过；如果不等，则测试失败。
}
```

**深度测试滤镜效果**

给物体添加两个pass，一个是正常显示的pass，另一个是滤镜效果的pass

滤镜效果的pass属性

```
Blend SrcAlpha One
ZTest Greater //核心
//这是深度测试（Z-Testing）的设置。深度测试用于确定哪些像素应该被绘制到屏幕上。
Greater 表示只有当当前像素的深度值大于深度缓冲区中的值时，才会绘制该像素。这通常用于实现一些特殊效果，如阴影或某些类型的贴图。
在正常情况下，深度测试通常设置为 Less 或 Lequal（小于或等于），以确保更近的物体遮挡更远的物体。但在某些特殊情况下，如实现阴影效果时，Greater 测试可能很有用。
ZWrite off
Cull Back //节省性能
```

<!-- endtab -->

<!-- tab 部分源代码展示-->



**效果实现代码**

```
  //视差算法实现代码
  float4 Parallax(in float2 uv,in float3 ViewTS,in float Depth,sampler2D _Map,float4 _Map_ST,in float Scale)
  {
      uv = uv* _Map_ST.xy*Scale+_Map_ST.zw  ;

      float CosAngle = dot(ViewTS,float3(0,0,1));
      float LengthAB = Depth/CosAngle;

      float3 UvA = float3(uv,0);
      float3 UvB = UvA + ViewTS*LengthAB;

      float4 Parallax = tex2D(_Map,saturate(UvB.xy));
      return Parallax;
 }
//贴图混合
 if(DepthMap+_BodyDepth > 0)
 {
    FinalDisplay = lerp(linesmap,body,body.a);
  
    FinalDisplay = lerp(background,FinalDisplay,FinalDisplay.a);
     
 }
else
{
    FinalDisplay =lerp(background,body,body.a);
   FinalDisplay =lerp(FinalDisplay,linesmap,linesmap.a);
                    
}
//高光与颜色
float3 hsvcolor =  pow(specularcolor * HSVToRGB(float3(uv.x*_LinesColorLenght+_LinesColor,1,1)).xyzz,_LinesColorPowScale.x)*_LinesColorPowScale.y;
            linesmap = linesmap.a*float4(hsvcolor,1)*_LinesTint ;
```

<!-- endtab -->

{% endtabs %}

## 仿原神卡通渲染

{% tabs 仿原神卡通渲染%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/mmd.mp4 %}
{% endvideos %}

{% tabs 视差卡片%}

<!-- tab 基本颜色-->

![2024-4-16 8_05_11](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725280.png)

<!-- endtab -->

<!-- tab LightMap.r;//金属高光部位-->

![2024-4-16 8_05_46](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725281.png)

<!-- endtab -->

<!-- tab LightMap.g;//光照偏移量，混合常暗区域（AO）;  -->

![2024-4-16 8_06_00](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725282.png)

<!-- endtab -->

<!-- tab **LightMap.a>_TestLayerNumber;//材质枚举**-->

{% gallery %}

![2024-4-16 8_07_22](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725283.png)

![2024-4-16 8_07_29](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725284.png)

![2024-4-16 8_07_36](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725285.png)

![2024-4-16 8_07_49](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725286.png)

![2024-4-16 8_07_54](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725287.png)

{% endgallery %}

<!-- endtab -->

<!-- tab 采样金属度贴图-->

![2024-4-16 8_09_07](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725288.png)

<!-- endtab -->

<!-- tab 漫反射-->

![2024-4-16 8_09_38](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725289.png)

<!-- endtab -->

<!-- tab 高光-->

![2024-4-16 8_10_10](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725290.png)

<!-- endtab -->

<!-- tab 环境光-->

![2024-4-18 6_44_50](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404180725291.png)

<!-- endtab -->

{% endtabs %}

<!-- endtab -->

<!-- tab 细节部分-->

## NPR仿原神渲染



**1. 准备资源**

收集并准备好所有必要的贴图，如纹理贴图、光照贴图等。

**2. 添加环境光**

- 应用Half Lambert光照模型。

**3. 明暗处理**

- 使用`smoothstep`函数，通过设定合适的阈值，实现模型表面明暗区域的过渡。
- 结合二分搜索或其他优化算法，快速而准确地确定明暗交界线，从而生成更具二次元风格的阴影效果。

**4. 材质与颜色处理**

- 利用光照贴图的alpha通道来识别不同材质区域，这样可以为每个区域应用不同的颜色处理方案。
- 通过ramp贴图技术，根据光照方向和表面法线，为模型表面添加二次元风格的颜色效果，使色彩更加丰富和生动。

**5. 高光处理**

- 采用Blinn-Phong光照模型来分别模拟金属和非金属的高光反射效果，为模型增加真实感和立体感。
- 通过提取光照贴图的R通道信息，强调金属部分的高光反射。

**6. 阴影混合**

- 将前面步骤中生成的阴影效果进行混合和调整，以增强模型的深度和层次感。
- 根据需要调整阴影的密度、颜色和位置，以达到最佳的视觉效果。

**7. 添加描边效果**

- 在模型的边缘添加明显的描边效果，以突出角色的轮廓和特征。

## MMD制作

1.场景布置

**背景采样与颜色混合**

根据输入的纹理坐标（`i.ase_texcoord2.xy`）和背景纹理的变换参数（`_BackGround_ST`），计算背景纹理的采样坐标`uv_BackGround`。

从背景纹理中采样颜色，并根据一系列参数（如背景颜色、星星亮度等）进行混合，得到初始的颜色值。

**雾效处理**

通过一系列的计算，包括标准化、距离计算和clamp操作，来确定雾效的影响程度。

使用`smoothstep`函数来平滑地过渡雾效的影响区域。

2.动作载入

准备好vmd动作文件，使用unity的MMD4插件，将PXM模型文件和vmd文件处理成FBX模型，使用动画控制器添加动作效果，在模型中添加组件

3.音频载入

使用videosourse组件添加相匹配的音频文件

<!-- endtab -->

<!-- tab 部分源代码展示-->

```
//=======漫反射=======//
  float lambert = saturate(NL);
  float halfLambert = pow(lambert * 0.5 + 0.5, 2);
  float halfLambertStep = smoothstep(0.423, 0.460, halfLambert);

  float rampU = clamp(smoothstep(0.2, 0.4, halfLambert), 0.005, 0.995);//阴影部分中的深浅是在0.2到0.4之间过渡
  float2 dayRampUV = float2(rampU, 1 - dayRampV);
  float2 nightRampUV = float2(rampU, 1 - nightRampV);
  float3 rampColor = lerp(tex2D(_RampMap, nightRampUV).rgb, tex2D(_RampMap, dayRampUV).rgb, _IsDay);//利用_isDay插值白天与黑夜的阴影颜色
  float3 shadowColor = lerp(BaseMap, BaseMap * rampColor, _LightThreshold) ;//* _ShaodwColor.rgb

  float3 diffuse = lerp(shadowColor, BaseMap, halfLambertStep);//明部到阴影是在0.423到0.460之间过渡的
  diffuse = lerp(shadowColor, diffuse, saturate(RampOffsetMask * 2));//将ILM贴图的g通道乘2 用saturate函数将超过1的部分去掉，混合常暗区域（AO）

  diffuse = lerp(diffuse, BaseMap, saturate(RampOffsetMask - 0.5) * 2);//将ILM贴图的g通道减0.5乘2 用saturate函数将小于0的部分去掉，混合常亮部分（眼睛）
  diffuse = diffuse+diffuse* _DiffuseColor.rgb*_LightColor0; //* _DiffuseColor.rgb;

//=======高光=======//
  // //高光反射
  float blinnPhong = step(0, NL) * pow(max(NH, 0), _MetallicStepSpecularWidth);
  float3 hairSpec = tex2D(_HairSpecMap, i.uv).rgb * blinnPhong * _HairSpecIntensity * BaseMap;
  float3 nonMetallicSpec = step(1.01 - blinnPhong, _MetallicStepSpecularWidth) * specIntensity * _NonMetallicSpecIntensity + hairSpec;//BlinnPhong取反做step用来限制非金属高光的区域
  float3 metallicSpec = blinnPhong * _MetallicStepSpecularWidth * halfLambertStep * BaseMap * _MetallicSpecIntensity;

  //计算金属、高光项
  float isMetal = step( 0.5,specIntensity);

  float3 specular = lerp(metallicSpec, nonMetallicSpec, isMetal)*_SpecularColor.rgb;
  float3 metallic = lerp(0, metallicIndensity, isMetal) * BaseMap * _MetallicIntensity;


  //混合
  float3 finalColor = diffuse  + metallic +specular;
//=======环境边缘光反射=======//
  fixed fresnel = 1.0 - dot(N, V);
  fresnel = lerp(fresnel, 2.0 - fresnel, step(1, fresnel));//由于开启了双面显示，当显示出来的面片为背面时，需要取2.0 - fresnel
  fresnel = smoothstep(_FresnelMin, _FresnelMax, fresnel);
  fixed3 reflectDir = reflect( - V, N);//反射光线方向
  //环境反射粗糙度
  float roughness = lerp(0.0, 0.95, saturate(_Roughness));
  roughness = roughness * (1.7 - 0.7 * roughness);
  float mipLevel = roughness * 6.0;
  //EnvironmentHDR贴图
  half4 cubemapColor = texCUBElod(_EnvironmentMap, float4(reflectDir, mipLevel));
  half3 environmentColor = DecodeHDR(cubemapColor, _EnvironmentMap_HDR);
  half3 environment = environmentColor * fresnel * _EnvironmentIntensity;
  
  //发射阴影
  UNITY_LIGHT_ATTENUATION(atten,  i,  i.worldPosition);
  
  
  //添加描边pass
  V2FData vert(MeshData v)
  {
      V2FData o;
      v.vertex.xyz += v.tangent.xyz *_OulineScale*0.01 * v.vertexColor.g ; //用顶点色的alpha通道控制描边粗细
      o.pos = UnityObjectToClipPos(v.vertex);
      o.color = v.vertexColor;
      return o;
  }
```

**场景代码**

![image-20240418100248875](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404181009622.png)

<!-- endtab -->

{% endtabs %}

## 体积云

{% tabs 体积云%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/VolumeCloud.mp4 %}
{% endvideos %}

<!-- endtab -->

<!-- tab 细节部分-->

**主光线追踪循环**

- 对于每条从摄像机发出的光线，进行固定步数的追踪（由`RaySteps`控制）。
- 在每一步，计算当前光线位置，并评估该位置的云密度和形状（通过调用`clouds`函数得到符号距离场SDF和密度）。
- 如果当前位置在云内部（SDF为负且密度大于0），则执行次级光线追踪来模拟光源对云的影响：
  - 沿着光源方向进行另一次光线追踪（由`LightSteps`控制）。
  - 在每一步中，评估当前光源光线位置处的云密度和形状。
  - 累积光学深度，用于后续的光照计算。
- 计算环境光照和直接光照对云的影响，得到当前位置的光照能量。
- 根据云的密度和光的吸收系数，更新光线的穿透率。
- 将计算得到的光照能量和穿透率累加到散射结果中。

循环结束处理

- 在完成所有光线追踪步骤后，根据一个全局的光强参数调整累积的光能量。
- 返回最终的散射结果，包括累积的光能量和穿透比率。这个结果可以用于后续的渲染流程，如颜色混合或透明度调整。

**3D贴图制作**

1.物体shader 使用**VFACE** 判断模正反 给予不同的颜色

2.shader 中调整裁剪clip的值，对模型进行切片,并使用相机将每片拍下来保存为Texture2D 数组

3.将保存的Texture2D数组 生成为Texture3D

4.将生成完的Texture3D 重新载入另一个shader进行模糊，再次切片 合成导出。

<!-- endtab -->

<!-- tab 部分源代码展示-->

```
UNITY_LOOP
for (int i = 0; i < RaySteps; ++i)
{
    float3 currentPos = begin + depth * dir;
    float sdf, density;
    clouds(currentPos, sdf, density);
    // Inside
    if (sdf < 0 && density > 0)
    {
        //沿着 光源方向，进行二次 RayMarching
        float3 beginPos2 = currentPos;
        float opticalDepth = 0;
        float t2 = 0;
        UNITY_LOOP
        for (int j = 0; j < LightSteps; ++j)
        {
            float3 currentPos2 = beginPos2 + t2 * L;
            float sdf2, density2;
            clouds(currentPos2, sdf2, density2);
            if (sdf2 < 0)
            {
                opticalDepth += LightStep * density2;
            }

            t2 += max(LightStep, sdf2);
            if (any(currentPos2 < -0.5) || any(currentPos2 > 0.5)) break;
            //跑到sdf形状外面去了
            // if(sdf2>0.1) break; 
        }

        // 模拟环境光照
        float3 ambient = 20*_LightColor0 * lerp(_AmbientColor1, _AmbientColor2, (currentPos.y*0.5 + 0.5)) * _AmbientIntensity* lerp(1,density,_AmbientDensity);
        float3 lightEnergy = 20*_LightColor0 * multipleOctaves(opticalDepth, cosTheta) * 3.14 * phase ;
        float3 currentColor = ambient + lightEnergy;

        float3 transmittance = exp(-step* _Absorption * density);

        //体积云 最核心的光照算法，就是这两行
        ScatteringResult.xyz += currentColor * (1.0 - transmittance) * ScatteringResult.w;
        ScatteringResult.w *= transmittance;
    }
    // 每次至少向前步进的距离
    depth += max(sdf, step);
    if (any(currentPos < -0.55) || any(currentPos > 0.55)) break;
}
```

<!-- endtab -->

{% endtabs %}

## 动态曲面细分

{% tabs 动态曲面细分%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/Tessellation.mp4 %}
{% endvideos %}

<!-- endtab -->

<!-- tab 细节部分-->

动态效果

1. 初始化（Start方法）
   - 脚本在开始时首先通过`Camera.main`获取主摄像机的引用，并存储在`mainCamera`变量中。
   - 接着，它调用`CreateRT`方法来创建三个渲染纹理：`TempRT`, `PrevRT`, `CurrentRT`。这些渲染纹理将用于后续的图像处理和效果应用。
   - 初始化`DrawMat`和`SnowMat`两个材质，并将它们分别与`DrawShader`和`SnowShader`着色器相关联。
   - 最后，它将当前对象的渲染器的纹理设置为`CurrentRT`，这意味着该对象将显示`CurrentRT`中的内容。
2. 绘制准备（每帧Update方法之前）
   - 在每帧更新之前，系统已经准备好了所有必要的资源，包括摄像机、渲染纹理和着色器材质。
3. 用户交互与绘制（Update方法中的射线检测部分）
   - 在每一帧中，脚本首先检查用户是否按下了鼠标左键。
   - 如果按下，脚本通过`mainCamera`执行一个从摄像机位置发射并经过鼠标在屏幕上的位置的射线。
   - 如果这个射线与场景中的任何物体相交（即发生了碰撞），则记录碰撞点的纹理坐标。
   - 使用记录的纹理坐标和预设的绘制半径，调用`DrawAt`方法来在`CurrentRT`的相应位置上“绘制”一个效果（可能是足迹或其他图形）。
4. 图像处理效果（Update方法中的计算部分）
   - 紧接着，脚本设置效果的衰减速度（`AttenSpeed`），这可能影响速度。
   - 使用`SnowMat`和两个渲染纹理（`PrevRT`和`CurrentRT`）来计算累积效果。这里`PrevRT`保存了上一帧的状态，而`CurrentRT`保存了当前帧的状态。
   - 通过`Graphics.Blit`方法，将处理后的图像输出到`TempRT`中，这个临时渲染纹理现在包含了更新后的效果。
5. 渲染纹理交换（Update方法的最后部分）
   - 为了在下一帧中保留当前帧的状态，脚本执行一系列渲染纹理的交换操作。
   - 首先，将`TempRT`的内容复制到`PrevRT`中，以便在下一帧中作为上一帧的数据使用。
   - 然后，将`CurrentRT`和`PrevRT`的引用交换，这样`CurrentRT`现在就包含了最新的效果，而`PrevRT`保存了前一帧的效果。
6. 渲染与显示
   - 随着每帧的更新，对象的渲染器将显示`CurrentRT`中的内容，这是最新计算出的效果。
   - 用户将继续看到根据他们的交互效果的累积与消融而动态变化的场景。

<!-- endtab -->

<!-- tab 部分源代码展示-->

曲面细分步骤

1. 常量外壳着色器（Constant Hull Shader, `ConstantHS`）
   - 此阶段计算整个曲面的细分级别。它接收原始的控制点（这里是三角形的三个顶点）作为输入，并基于这些控制点计算出一个细分因子（`fac`）。
   - 在这个例子中，细分因子是根据纹理采样结果和某些预设参数（如`_maxVal`, `_minVal`, `_factor`）通过`smoothstep`函数动态计算的。
   - 计算出细分因子后，它会被应用到三角形的每条边和内部，决定曲面将被细分成多少个小三角形。
2. 外壳着色器（Hull Shader, `hullProgram`）
   - 在常量外壳着色器之后，外壳着色器为每个细分后的控制点（这里是每个原始控制点的细分版本）计算输出数据。
   - 这个阶段主要为每个控制点准备如世界位置、纹理坐标、法线等必要的插值数据，这些数据将在后续的域着色器中使用。
3. 曲面细分
   - 基于常量外壳着色器计算出的细分因子，硬件会执行实际的曲面细分操作，生成更多的三角形来逼近原始曲面。
4. 域着色器（Domain Shader, `domainProgram`）
   - 域着色器运行在细分后的每个小三角形上。它接收由外壳着色器准备的插值数据和细分后小三角形的重心坐标作为输入。
   - 使用这些输入数据，域着色器计算出每个细分三角形的顶点属性，如位置、纹理坐标、法线等。
   - 这些顶点属性是通过原始控制点的属性进行线性插值得到的。
5. 几何着色器/光栅化
   - 在某些情况下，曲面细分之后可能还会有一个几何着色器阶段，用于进一步处理细分后的几何图形。
   - 然后，这些几何数据将被光栅化，转换为屏幕空间的像素，以供像素着色器处理。
6. 像素着色器
   - 最后，在像素着色器阶段，将处理光栅化后的像素，应用纹理、光照等效果，并最终输出到屏幕上。

```
//vert顶点程序之后调用，计算细分前的三角形顶点信息
			TessOut hullProgram(InputPatch<v2t, 3> i, uint idx : SV_OutputControlPointID)
			{
				TessOut o;
				o.worldPos = i[idx].worldPos;
				o.uv = i[idx].uv;
				o.normalWS = i[idx].normalWS;
				o.normalOS = i[idx].normalOS;
				o.pos = i[idx].pos;
				o.tangent = i[idx].tangent;
				o.bitangent = i[idx].bitangent;
				return o;
			}

			//指定每个边的细分段数和内部细分段数
			TessParam ConstantHS(InputPatch<v2t, 3> i, uint id : SV_PrimitiveID)
			{
				TessParam o;
				float2 uv =(i[0].uv+i[1].uv+i[2].uv)/3;
				
				
				float4 worldPos = (i[0].worldPos + i[1].worldPos + i[2].worldPos) / 3;
				float4 pos = (i[0].pos + i[1].pos + i[2].pos) / 3;//

				float4 tex = tex2Dlod(_MainTex,float4(uv,0,0))+(1-pos.y);
				
				float smoothstepResult = smoothstep(_maxVal,_minVal , tex);
				
				float fac = max((1.0 - smoothstepResult)*_factor, 1);
				
				//由于我这里是根据指定的中心点和半径范围来动态算细分段数，所以才有这个计算，不然可以直接指定变量来设置。
				o.EdgeTess[0] = fac;
				o.EdgeTess[1] = fac;
				o.EdgeTess[2] = fac;
				o.InsideTess = fac;
				return o;
			}

			//在domainProgram前必须设置domain参数，不然会报错
			[domain("tri")]
			//细分之后，把信息传到frag片段程序
			t2f domainProgram(TessParam tessParam, float3 bary : SV_DomainLocation, const OutputPatch<TessOut, 3> i)
			{
				t2f o;				
				//线性转换
				o.worldPos = i[0].worldPos * bary.x + i[1].worldPos * bary.y + i[2].worldPos * bary.z;
				o.clipPos = UnityWorldToClipPos(o.worldPos);
				float2 uv = i[0].uv * bary.x + i[1].uv * bary.y + i[2].uv * bary.z;
				o.uv = uv;
				o.pos = i[0].pos* bary.x+ i[1].pos * bary.y + i[2].pos * bary.z;
				o.normalWS = i[0].normalWS* bary.x+ i[1].normalWS * bary.y + i[2].normalWS* bary.z;
				o.normalOS = i[0].normalOS* bary.x+ i[1].normalOS * bary.y + i[2].normalOS* bary.z;
				o.tangent = i[0].tangent* bary.x+ i[1].tangent * bary.y + i[2].tangent* bary.z; 
				o.bitangent = i[0].bitangent* bary.x+ i[1].bitangent * bary.y + i[2].bitangent* bary.z;
			
				return o;
			}
```

<!-- endtab -->

{% endtabs %}

## 后处理shader

{% tabs 后处理效果%}

<!-- tab 渲染效果-->

{% tabs 后处理效果展示%}

<!-- tab 黑白漫画效果-->

![2024-4-16 11_10_11](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934874.png)

<!-- endtab -->

<!-- tab 暗角效果-->

![2024-4-16 11_10_45](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240940392.png)

<!-- endtab -->

<!-- tab 扰动效果-->

![2024-4-16 11_10_57](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934876.png)

<!-- endtab -->

<!-- tab 油画效果-->

![2024-4-16 11_11_03](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934877.png)

<!-- endtab -->

<!-- tab 模糊效果-->

![2024-4-16 11_11_13](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934878.png)

<!-- endtab -->

{% endtabs %}

<!-- endtab -->

<!-- tab 部分源代码展示-->

```
           float3 Oil(float2 uv)
            {
                float4 normalmap = tex2D(_OilNormalMap,uv);
                UnpackNormal(normalmap);

                float2 Coloruv = uv + normalmap.xy*_OilIndensity  * 0.01;

                float3 Color = tex2D(_MainTex,Coloruv);

                float3 hsv = RGBToHSV(Color);
                Color.rgb = HSVToRGB(hsv + float3(0,0.29,-0.07));

                // normalmap = pow(normalmap,_OilRange) * _OilIndensity;

                
                return Color;
            }

            float3 Vague(float2 uv)
            {
                
                float4 View = float4(0,0,0,0);

                for(int x = -_VagueLevel;x <=_VagueLevel;x++)
                {
                    for(int y = -_VagueLevel;y<=_VagueLevel;y++)
                    {
                        float2 offset = float2(x*_VagueScale,y*_VagueScale)*0.001;
                        View += tex2D(_MainTex,uv + offset);
                    }
                }
                View /= (_VagueLevel * 2 +1) * (_VagueLevel * 2 + 1);

                return View.xyz;
            }


            float3 Cartoon(float2 uv)
            {
                float2 Cartoonuv = uv;

                Cartoonuv = Cartoonuv*_NoisePowScaleUVScale.z;
                
                float3 Color = tex2D(_MainTex,uv);
                float3 Noise = tex2D(_NoiseMap,Cartoonuv);
                
             
                Noise = pow(Noise,_NoisePowScaleUVScale.x)*_NoisePowScaleUVScale.y;
                if(_ChangeLight)
                {
                    Color  =  Color+Noise;
                    Color = Color.r > Luminance(_luminanceVale);                    
                }
                else
                {
                    if(Color.r <  Luminance(_luminanceVale))
                    {
                        Color += Noise;
                    }
                        
                }
                        
                return Color.r;
            }


            float3 DackCorner(float2 uv)
            {
                float3 Color = tex2D(_MainTex,uv);
                float2 Center=float2(0.5,0.5);
                

                float Range = saturate(_DackRange - distance(Center,uv));

                Range = saturate(pow(Range,_DackPowScale.x) * _DackPowScale.y);

                return Color*Range;
            }

            float3 Disturbance(float2 uv)
            {
                
              
                float3 disturbancemap = tex2D(_DisturbanceMap,(uv + float2(_DisturbanceDirecter.x,_DisturbanceDirecter.y)*_Time*_DisturbanceSpeed) *_DisturbanceIndensity*0.01);
                
                float2 disturbanceuv;
                disturbanceuv = uv + _DisturbanceRange*disturbancemap;

                float3 Color = tex2D(_MainTex,disturbanceuv);

                return Color;
            }
```

<!-- endtab -->

{% endtabs %}

## 水墨风格shader

{% tabs 水墨风格片%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/Ink.mp4 %}
{% endvideos %}

<!-- endtab -->

<!-- tab 细节部分-->

1. 处理光照信息
   - 首先，对输入的法线进行归一化。
   - 获取场景中的主光源信息，包括光源方向和阴影衰减。
2. 应用噪声扰动
   - 使用噪声纹理（`_InteriorNoise`）对输入的纹理坐标进行扰动，得到一个噪声值。
   - 结合另一个纹理（`_StrokeTex`）和一些调整参数，对原始的纹理坐标进行修改，得到一个新的坐标。
3. 限制坐标范围
   - 确保新坐标的值不超过某个上限（如0.95），并进行范围限制，使其在0到1之间。
4. 执行高斯模糊
   - 初始化一个用于累加的颜色变量。
   - 在新坐标周围按照高斯分布采样一个颜色纹理（`_Ramp`），对每个采样点的颜色进行加权累加，以实现模糊效果。
5. 合成最终颜色
   - 将高斯模糊后的颜色作为最终的颜色输出（在这个特定的代码版本中，阴影效果被注释掉了，所以不考虑阴影衰减）。

<!-- endtab -->

<!-- tab 部分源代码展示-->

```
  float4 burn = tex2D(_InteriorNoise, i.uv);
  // a little bit disturbance on normal vector
  float diff =  dot(worldNormal, worldLightDir);
  diff = pow((diff * 0.5 + 0.5),_darkPow);
  float2 k = tex2D(_StrokeTex, i.uv).xy;
  float2 cuv = float2(diff, diff) + k * burn.xy * _InteriorNoiseLevel;
  // return burn;

  // This iniminate the bias of the uv movement?
  if (cuv.x > 0.95)
  {
    cuv.x = 0.95;
    cuv.y = 1;
  }
  if (cuv.y >  0.95)
  {
    cuv.x = 0.95;
    cuv.y = 1;
  }
  cuv = clamp(cuv, 0, 1);

  //Guassian Blur
  float4 sum = float4(0.0, 0.0, 0.0, 0.0);
          float2 tc = cuv;
          //blur radius in pixels
          float blur = radius/resolution/4;
```

<!-- endtab -->

{% endtabs %}

## 风格化水面

{% tabs 风格化水面%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/Water.mp4 %}
{% endvideos %}

{% gallery %}

![2024-4-24 9_05_55](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934879.png)

![2024-4-24 9_08_51](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934880.png)

![2024-4-24 9_09_09](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934881.png)

![2024-4-24 9_13_36](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934882.png)

![2024-4-24 9_13_55](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934883.png)

![2024-4-24 9_14_29](https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/202404240934884.png)

{% endgallery %}

<!-- endtab -->

<!-- tab 细节部分-->

波浪效果

- 通过引入时间依赖的扰动函数，在顶点着色器中动态调整顶点位置，创造出逼真的波浪起伏效果。

 反射效果

- 利用屏幕空间反射（SSR）或平面反射（PR）技术，实现水面上的高质量反射。通过添加适当的模糊效果，进一步提升SSR的视觉效果，增加场景深度感。

 泡沫、涟漪与焦散

- 应用焦散贴图，模拟光线折射和反射效果，形成焦散光斑。同时，通过动态调整贴图的UV坐标，增添生动的泡沫和涟漪效果。

光照效果

- 采用Half Lambert光照模型增强漫反射效果。
- 结合Blinn-Phong高光模型，模拟真实的高光反射，提升水面的视觉质感。

<!-- endtab -->

<!-- tab 部分源代码展示-->

```
 //===================== Foam 边缘水花=======================================================================
#ifdef USE_FOAM
    // return _NoiseMap.Sample(sampler_NoiseMap,  input.positionWS.xz*0.1 + float2(_Time.x*2,0));
    float foamDistance = 1- saturate(depthDistance/2);
    //从中间往 岸边动
    float foamDynamic = 0.5* step( _FoamWidth,frac(foamDistance - _Time.y*0.1*_FoamSpeed + noise.r*0.0325)) * foamDistance*foamDistance;

    //浪花衰减
    foamDynamic = _EnableDynamicFoam*foamDynamic* smoothstep( _FoamFadeDistance ,1,foamDistance);
    float foamStatic =  0.5 *step( _FoamWidth,frac(foamDistance  + noise.r*0.03525)) * foamDistance*foamDistance;
    float foam = max(foamDynamic,foamStatic);

    //加点噪音举出
    float foamNoise = SAMPLE_TEXTURE2D(_FoamNoiseMap, sampler_FoamNoiseMap,positionWS.xz*_FoamNoiseMap_ST.xy);
    foamNoise = saturate( pow(foamNoise,_FoamNoisePowScaleVec.x) *_FoamNoisePowScaleVec.y);

    finalColor += foam*LightLum*_FoamColor*foamNoise* saturate(dot(N,V));

#endif

//===================== Caustic 模拟焦散 =================================
//用深度图的世界坐标采样 CausticMap 模拟其在水中晃动的感觉
//贴图焦散

#ifndef  USE_PROCEDURAL_CAUSTIC
    float4 caustic = SAMPLE_TEXTURE2D(_CausticMap, sampler_CausticMap, depthWorldPosition.xz*0.2*_CausticMap_ST.xy+distortionUV*5);
    // float4 caustic = SAMPLE_TEXTURE2D(_CausticMap, sampler_CausticMap, positionWS.xz*0.2*_CausticMap_ST.xy+distortionUV*5);
#else
//程序化焦散
    float4 caustic =GetCaustic(depthWorldPosition*0.4*_CausticUVScale+distortionUV.xyy*5 + float3(0,_Time.x,0)).xyzz;
#endif

caustic *= smoothstep(_CausticFade,1, (1-distortionDistanceFade) )*_CausticIntensity*NL01;
finalColor += caustic*LightLum* mainLight.shadowAttenuation;
```

<!-- endtab -->

{% endtabs %}

## 森林遗迹

{% tabs 森林遗迹%}

<!-- tab 渲染效果-->

{% videos %}
{% video https://yin-qin.oss-cn-shanghai.aliyuncs.com/XiaoYao/VideoPass/forest.mp4 %}
{% endvideos %}

<!-- endtab -->

{% endtabs %}

## 工具脚本制作

{% tabs 视差卡片%}

<!-- tab mesh合并工具-->

```
public class MeshMergerEditor : EditorWindow  
{  
    [MenuItem("Tools/Merge Meshes")]  
    private static void MergeSelectedMeshes()  
    {  
        // 获取当前选中的GameObject  
        GameObject[] selectedObjects = Selection.gameObjects;  
        List<Mesh> meshesToMerge = new List<Mesh>();  
  
        // 遍历选中的GameObject，获取它们的MeshFilter组件中的网格  
        foreach (GameObject obj in selectedObjects)  
        {  
            MeshFilter meshFilter = obj.GetComponent<MeshFilter>();  
            if (meshFilter != null)  
            {  
                meshesToMerge.Add(meshFilter.sharedMesh);  
            }  
        }  
  
        // 如果没有选中任何网格或者选中的GameObject没有MeshFilter组件，则返回  
        if (meshesToMerge.Count == 0)  
        {  
            Debug.LogError("No meshes selected to merge.");  
            return;  
        }  
  
        // Prepare combine instances  
        CombineInstance[] combineInstances = new CombineInstance[meshesToMerge.Count];  
        for (int i = 0; i < meshesToMerge.Count; i++)  
        {  
            combineInstances[i].mesh = meshesToMerge[i];  
            combineInstances[i].transform = Matrix4x4.identity;  
        }  
  
        // Create a new mesh to hold the combined meshes  
        Mesh combinedMesh = new Mesh();  
        combinedMesh.CombineMeshes(combineInstances);  
        combinedMesh.name = "MergedMesh_" + System.DateTime.Now.ToString("yyyyMMddHHmmss");  
  
        // Create a new GameObject to hold the merged mesh  
        GameObject mergedMeshObject = new GameObject("MergedMeshObject");  
        mergedMeshObject.AddComponent<MeshFilter>().mesh = combinedMesh;  
        mergedMeshObject.AddComponent<MeshRenderer>(); // Optionally add a MeshRenderer  
  
        // Place the merged mesh object at the world origin by default  
        mergedMeshObject.transform.position = Vector3.zero;  
  
        // Select the new merged mesh object in the Hierarchy view  
        Selection.activeObject = mergedMeshObject;  
  
        // Optionally, you can save the mesh as an asset  
        string path = EditorUtility.SaveFilePanel("Save Merged Mesh", "", combinedMesh.name + ".mesh", "mesh");  
        if (!string.IsNullOrEmpty(path))  
        {  
            AssetDatabase.CreateAsset(combinedMesh, path);  
            AssetDatabase.SaveAssets();  
            AssetDatabase.Refresh();  
        }  
    }  
}
```

<!-- endtab -->

<!-- tab 3D贴图制作工具-->

```
using System;
using System.Collections;
using System.Collections.Generic;
using UnityEditor;
using UnityEngine;
[ExecuteInEditMode]
public class Render3DTexture : MonoBehaviour {

    public Vector3 Size = Vector3.one;
    public Vector3 Offset = Vector3.zero;

    public Vector3Int TextureSize = new Vector3Int(256,256,256);

    private Camera renderCam;

    private RenderTexture renderTexture;

    private Texture3D volumeTex;

    public Material SliceMat;

    public Material BlurMat;

    public bool Blur = false;



    //public List<Texture2D> textureArray = new List<Texture2D>();

    [Range(0,1.0f)]
    public float ClipValueRange = 0;
    private float ClipValue = -0.5f;
    [Tooltip("输出路径")]
    public string OutputPath = "testAsset1.asset";


    /// <summary>
    /// 生成相机
    /// </summary>
    private void NewCam()
    {
        GameObject cam = new GameObject("TempCam");

        cam.transform.position = transform.position + Size.y *0.51f *Vector3.up +Offset;

        Vector3 localEuler = cam.transform.localEulerAngles;

        localEuler.x = 90;
        localEuler.y = 180;

        cam.transform.localEulerAngles = localEuler;

        renderCam = cam.AddComponent<Camera>();

        renderCam.orthographic = true;

        renderCam.orthographicSize = Size.x*0.5f;

        renderCam.nearClipPlane = 0.0001f;
        renderCam.farClipPlane = 100;

        renderCam.clearFlags = CameraClearFlags.SolidColor;

        renderCam.backgroundColor = Color.black;

        renderTexture = CreateRT(TextureSize.x, TextureSize.z);

        renderCam.targetTexture = renderTexture;

    }

    public void StartRender()
    {
        NewCam();

        volumeTex = new Texture3D(TextureSize.x, TextureSize.y, TextureSize.z,TextureFormat.RFloat,false);

        RenderSlice();
    }

    public void RenderSlice()
    {

        //渲染范围
        Vector3 center = transform.position;
        float min = -Size.y * 0.5f + Offset.y + center.y;
        float max = Size.y * 0.5f + Offset.y + center.y;

        ClipValue = min;

        Color[] colors = new Color[TextureSize.x * TextureSize.y * TextureSize.z];

        int layerCount = TextureSize.x * TextureSize.z;

        for (int layer = 0; layer < TextureSize.y; layer++)
        {
            renderCam.Render();

            ClipValue += (max - min) / TextureSize.y;

            float progress = (float)layer / TextureSize.y;

            bool isCancel = EditorUtility.DisplayCancelableProgressBar("正在执行..",string.Format("生成3DTexture中... {0:f2}%", progress*100), progress);

            if (SliceMat != null)SliceMat.SetFloat("_ClipValue", ClipValue);

            Texture2D sliceTex = RenderTexture2Texture2D(renderTexture);


            int index = 0;
            //拷贝颜色
            for (int z = 0; z < TextureSize.z; z++)
                for (int x = 0; x < TextureSize.x; x++)
                {
                    //XY ->XZ
                    index = x + z * TextureSize.y * TextureSize.x+layer* TextureSize.x;
                    colors[index] = sliceTex.GetPixel(x, z);
                }
            //渲染完成或者取消时关闭进度条
            if (layer >= TextureSize.y - 1 || isCancel)
            {
                EditorUtility.ClearProgressBar();

                if (isCancel)
                {
                    DestroyImmediate(renderCam.gameObject);
                    renderTexture.Release();

                    return;
                }
            }
        }

        volumeTex.SetPixels(colors);
        volumeTex.Apply();
        if (Blur)
        {
            volumeTex = BlurTexture(volumeTex);
        }
        string filePath = "Assets/"+ OutputPath;
        try
        {
            AssetDatabase.DeleteAsset(filePath);
            AssetDatabase.CreateAsset(volumeTex, filePath);
        }
        catch (Exception ex)
        {
            Debug.LogError(ex.Message);
        }
        DestroyImmediate(renderCam.gameObject);
        renderTexture.Release();
        renderTexture = null;
        UnityEditor.AssetDatabase.SaveAssets();
        AssetDatabase.Refresh();
    }
    /// <summary>
    /// Renderer转成Texture2D
    /// </summary>
    /// <param name="rt"></param>
    /// <returns></returns>
    public Texture2D RenderTexture2Texture2D(RenderTexture rt)
    {
        RenderTexture preRT = RenderTexture.active;
        RenderTexture.active = rt;
        Texture2D tex = new Texture2D(rt.width, rt.height, TextureFormat.ARGB32, false);
        tex.ReadPixels(new Rect(0, 0, rt.width, rt.height), 0, 0);
        tex.Apply();
        RenderTexture.active = preRT;
        return tex;
    }

    public void OnDrawGizmos()
    {
        Gizmos.DrawWireCube(this.transform.position+Offset, Size);
    }

    public void OnDestory()
    {
        renderTexture.Release();
    }

    public Texture3D BlurTexture(Texture3D tex)
    {
        for (int i = 0; i < 2; i++)
        {
            Color[] colors = new Color[TextureSize.x * TextureSize.y * TextureSize.z];

            int index = 0;

            for (int layer = 0; layer < TextureSize.y; layer++)
            {
                BlurMat.SetTexture("_VolumeTex", tex);
                BlurMat.SetFloat("_offset", layer * 1.0f / TextureSize.y);
                Debug.Log(layer * 1.0f / TextureSize.y);

                RenderTexture rt = new RenderTexture(TextureSize.x, TextureSize.z, 24, RenderTextureFormat.ARGB32);

                Graphics.Blit(null, rt, BlurMat);

                Texture2D sliceTex = RenderTexture2Texture2D(rt);

                //拷贝颜色
                for (int z = 0; z < TextureSize.z; z++)
                    for (int x = 0; x < TextureSize.x; x++)
                    {
                        //XY ->XZ
                        index = x + z * TextureSize.y * TextureSize.x + layer * TextureSize.x;
                        colors[index] = sliceTex.GetPixel(x, z);
                    }
            }

            tex.SetPixels(colors);
            tex.Apply();
        }
        return tex;
    }

    private RenderTexture CreateRT(int width, int height)
    {
        RenderTexture rt = new RenderTexture(width, height, 16);
        rt.format = RenderTextureFormat.ARGBFloat;
        rt.wrapMode = TextureWrapMode.Repeat;
        rt.filterMode = FilterMode.Point;
        rt.Create();
        return rt;
    }
    
    private void Update()
    {
        if (SliceMat == null)
        {
            SliceMat = GetComponent<Renderer>().sharedMaterial;
        }
        if (SliceMat != null)
        {
            float min = -Size.y * 0.5f + Offset.y+transform.position.y;
            float max = Size.y * 0.5f + Offset.y +transform.position.y;
            float value = Mathf.Lerp(min, max, ClipValueRange);
            SliceMat.SetFloat("_ClipValue", value);
        }

    }
}

```

<!-- endtab -->

<!-- tab 动态贴图制作工具-->

```
using System.Collections;
using System.Collections.Generic;
using Palmmedia.ReportGenerator.Core.Parser.Analysis;
using UnityEngine;

public class Interactive : MonoBehaviour
{

    public Camera mainCamera;

    public RenderTexture TempRT;
    
    
    public Shader DrawShader;

    private Material DrawMat;
    public int TextureSize = 512;

    [Range(0,1.0f)]
    public float DrawRadius = 0.5f;

    
    public RenderTexture PrevRT;//上一帧RT
    //public RenderTexture CurrentRT;//当前帧RT
    public RenderTexture CurrentRT;
    public Shader SnowShader;
    private Material SnowMat;
        
    [Range(0,1)]
    public float AttenSpeed = 0.5f;
    
    
    // Start is called before the first frame update
    void Start()
    {
        mainCamera = Camera.main.GetComponent<Camera>();
        CurrentRT = CreateRT();
        PrevRT = CreateRT();
        TempRT = CreateRT();

        DrawMat = new Material(DrawShader);
        SnowMat = new Material(SnowShader);

        GetComponent<Renderer>().material.mainTexture = CurrentRT;
    }

    public RenderTexture CreateRT()
    {
        RenderTexture rt = new RenderTexture(TextureSize, TextureSize, 0, RenderTextureFormat.RFloat);
        rt.Create();
        return rt;
    }


    private void DrawAt(float x,float y, float radius)
    {
        //原来的贴图
        DrawMat.SetTexture("_SourceTex",CurrentRT);
        //绘制的大小和位置
        DrawMat.SetVector("_Pos",new Vector4(x,y,radius));
        //输出
        Graphics.Blit(null,TempRT,DrawMat);
        //进行交换
        RenderTexture rt = TempRT;
        TempRT = CurrentRT;
        CurrentRT = rt;
    }
    
    // Update is called once per frame
    void Update()
    {
        Shader.SetGlobalFloat("_AttenSpeed",AttenSpeed);
        //射线检测
        if (Input.GetMouseButton(0))
        {
            //鼠标左键按下时进行检测
            Ray ray = mainCamera.ScreenPointToRay(Input.mousePosition);
            //获取碰撞信息
            RaycastHit hit;
            if (Physics.Raycast(ray,out hit))
            {
                //绘制
                DrawAt(hit.textureCoord.x, hit.textureCoord.y, DrawRadius);
            }

        }
        
        //计算
        SnowMat.SetTexture("_PrevRT",PrevRT);
        SnowMat.SetTexture("_CurrentRT",CurrentRT);
        Graphics.Blit(null,TempRT,SnowMat);
        //交换RT
        Graphics.Blit(TempRT,PrevRT);
        RenderTexture rt = PrevRT;
        PrevRT = CurrentRT;
        CurrentRT = rt;

    }
}

```

<!-- endtab -->

<!-- tab 镜子工具-->

```
using System;
using System.Collections;
using System.Collections.Generic;
using UnityEngine;
using UnityEngine.Rendering;


[ExecuteInEditMode]
public class PlanarReflection : MonoBehaviour {
    public LayerMask _reflectionMask = -1;
    public bool _reflectSkybox = false;
    Color _clearColor = Color.black;
    public int m_TextureSize = 1024;

    const string _reflectionSampler = "_ReflectionTex";
    public float _clipPlaneOffset = 0.07F;

    Vector3 _oldpos;
    Camera _reflectionCamera;
    RenderTexture _bluredReflectionTexture;
    Material _sharedMaterial;

    public bool _blurOn = true;

       

    [Range(0.0f, 5.0f)]
    public float _blurSize = 1;
    public int _blurIterations = 2;
    public float _downsample = 1;

#if UNITY_EDITOR
    bool _oldBlurOn;
    float _oldBlurSize;
#endif

    private Shader _blurShader;
    private Material _blurMaterial;

    private static bool s_InsideWater;
    private RenderTexture rt;

    Material BlurMaterial {
        get {
            if (_blurMaterial == null) {
                _blurMaterial = new Material(_blurShader);
                return _blurMaterial;
            }
            return _blurMaterial;
        }
    }

#if UNITY_EDITOR
    void Awake() {
        _oldBlurOn = _blurOn;
        _oldBlurSize = _blurSize;

    }
#endif

    void Start() {
        _sharedMaterial = GetComponent<MeshRenderer>().sharedMaterial;
        if (_blurShader == null)
            _blurShader = Shader.Find("Hidden/SimpleBlur");
    }


    Camera CreateReflectionCameraFor(Camera cam) {
        String reflName = gameObject.name + "Reflection" + cam.name;
        GameObject go = new GameObject(reflName);
        go.hideFlags = HideFlags.HideAndDontSave;
        Camera reflectCamera = go.AddComponent<Camera>();

        reflectCamera.backgroundColor = _clearColor;
        reflectCamera.clearFlags = _reflectSkybox ? CameraClearFlags.Skybox : CameraClearFlags.SolidColor;

        SetStandardCameraParameter(reflectCamera, _reflectionMask);

        if (!reflectCamera.targetTexture) {
            reflectCamera.targetTexture = CreateTexture();
        }

        return reflectCamera;
    }

    void SetStandardCameraParameter(Camera cam, LayerMask mask) {
        cam.cullingMask = mask;
        cam.backgroundColor = Color.black;
        cam.enabled = false;
    }

    RenderTexture CreateTexture() {
#if UNITY_EDITOR
        //RenderTexture rt = new RenderTexture(Mathf.FloorToInt(Screen.width), Mathf.FloorToInt(Screen.height * 0.5f), 16);
        rt = new RenderTexture(m_TextureSize, m_TextureSize, 16);
        
#else
        //RenderTexture rt = new RenderTexture(Mathf.FloorToInt(Screen.width * 0.5f), Mathf.FloorToInt(Screen.height * 0.5f), 16);
        RenderTexture rt = new RenderTexture(m_TextureSize,m_TextureSize, 16);

#endif
        rt.hideFlags = HideFlags.DontSave;
        return rt;
    }

    void OnWillRenderObject() {
        Camera currentCam = Camera.current;
        if (!currentCam) {
            return;
        }

#if !UNITY_EDITOR
        if (!currentCam.gameObject.CompareTag("MainCamera"))
            return;
#endif

#if UNITY_EDITOR
        if (!_bluredReflectionTexture)
            _bluredReflectionTexture = CreateTexture();
#else
        if(_blurOn) {
            if (!_bluredReflectionTexture)
                _bluredReflectionTexture = CreateTexture();
        }
#endif

        if (s_InsideWater) {
            return;
        }
        s_InsideWater = true;


        if (!_reflectionCamera) {
            _reflectionCamera = CreateReflectionCameraFor(currentCam);
        }

        RenderReflectionFor(currentCam, _reflectionCamera);

        if (_reflectionCamera && _sharedMaterial) {
            if (_blurOn) {
                PostProcessTexture(currentCam, _reflectionCamera.targetTexture, _bluredReflectionTexture);
                _sharedMaterial.SetTexture(_reflectionSampler, _bluredReflectionTexture);
            } else {
                _sharedMaterial.SetTexture(_reflectionSampler, _reflectionCamera.targetTexture);
            }
        }

        s_InsideWater = false;
    }

#if UNITY_EDITOR
    bool _blurParamChanged;
    void Update() {
        if (_blurParamChanged) {
            _oldBlurOn = _blurOn;
            _oldBlurSize = _blurSize;
        }

        if (_blurOn != _oldBlurOn || _blurSize != _oldBlurSize) {
            _blurParamChanged = true;
        }

    }
#endif

    void RenderReflectionFor(Camera cam, Camera reflectCamera) {
        if (!reflectCamera) {
            return;
        }

        if (_sharedMaterial && !_sharedMaterial.HasProperty(_reflectionSampler)) {
            return;
        }

        reflectCamera.cullingMask = _reflectionMask;

        SaneCameraSettings(reflectCamera);

        reflectCamera.backgroundColor = _clearColor;
        reflectCamera.clearFlags = _reflectSkybox ? CameraClearFlags.Skybox : CameraClearFlags.SolidColor;
        if (_reflectSkybox) {
            if (cam.gameObject.GetComponent(typeof(Skybox))) {
                Skybox sb = (Skybox)reflectCamera.gameObject.GetComponent(typeof(Skybox));
                if (!sb) {
                    sb = (Skybox)reflectCamera.gameObject.AddComponent(typeof(Skybox));
                }
                sb.material = ((Skybox)cam.GetComponent(typeof(Skybox))).material;
            }
        }

        bool isInvertCulling = GL.invertCulling;
        GL.invertCulling = true;

        Transform reflectiveSurface = transform; //waterHeight;

        Vector3 eulerA = cam.transform.eulerAngles;

        reflectCamera.transform.eulerAngles = new Vector3(-eulerA.x, eulerA.y, eulerA.z);
        reflectCamera.transform.position = cam.transform.position;

        Vector3 pos = reflectiveSurface.transform.position;
        pos.y = reflectiveSurface.position.y;
        Vector3 normal = reflectiveSurface.transform.up;
        float d = -Vector3.Dot(normal, pos) - _clipPlaneOffset;
        Vector4 reflectionPlane = new Vector4(normal.x, normal.y, normal.z, d);

        Matrix4x4 reflection = Matrix4x4.zero;
        reflection = CalculateReflectionMatrix(reflection, reflectionPlane);
        _oldpos = cam.transform.position;
        Vector3 newpos = reflection.MultiplyPoint(_oldpos);

        reflectCamera.worldToCameraMatrix = cam.worldToCameraMatrix * reflection;

        Vector4 clipPlane = CameraSpacePlane(reflectCamera, pos, normal, 1.0f);

        Matrix4x4 projection = cam.projectionMatrix;
        projection = CalculateObliqueMatrix(projection, clipPlane);
        reflectCamera.projectionMatrix = projection;

        reflectCamera.transform.position = newpos;
        Vector3 euler = cam.transform.eulerAngles;
        reflectCamera.transform.eulerAngles = new Vector3(-euler.x, euler.y, euler.z);

        reflectCamera.Render();

        GL.invertCulling = isInvertCulling;
    }


    void SaneCameraSettings(Camera helperCam) {
        helperCam.depthTextureMode = DepthTextureMode.None;
        helperCam.backgroundColor = Color.black;
        helperCam.clearFlags = CameraClearFlags.SolidColor;
        helperCam.renderingPath = RenderingPath.Forward;
    }


    static Matrix4x4 CalculateObliqueMatrix(Matrix4x4 projection, Vector4 clipPlane) {
        Vector4 q = projection.inverse * new Vector4(
            Sgn(clipPlane.x),
            Sgn(clipPlane.y),
            1.0F,
            1.0F
            );
        Vector4 c = clipPlane * (2.0F / (Vector4.Dot(clipPlane, q)));
        // third row = clip plane - fourth row
        projection[2] = c.x - projection[3];
        projection[6] = c.y - projection[7];
        projection[10] = c.z - projection[11];
        projection[14] = c.w - projection[15];

        return projection;
    }


    static Matrix4x4 CalculateReflectionMatrix(Matrix4x4 reflectionMat, Vector4 plane) {
        reflectionMat.m00 = (1.0F - 2.0F * plane[0] * plane[0]);
        reflectionMat.m01 = (-2.0F * plane[0] * plane[1]);
        reflectionMat.m02 = (-2.0F * plane[0] * plane[2]);
        reflectionMat.m03 = (-2.0F * plane[3] * plane[0]);

        reflectionMat.m10 = (-2.0F * plane[1] * plane[0]);
        reflectionMat.m11 = (1.0F - 2.0F * plane[1] * plane[1]);
        reflectionMat.m12 = (-2.0F * plane[1] * plane[2]);
        reflectionMat.m13 = (-2.0F * plane[3] * plane[1]);

        reflectionMat.m20 = (-2.0F * plane[2] * plane[0]);
        reflectionMat.m21 = (-2.0F * plane[2] * plane[1]);
        reflectionMat.m22 = (1.0F - 2.0F * plane[2] * plane[2]);
        reflectionMat.m23 = (-2.0F * plane[3] * plane[2]);

        reflectionMat.m30 = 0.0F;
        reflectionMat.m31 = 0.0F;
        reflectionMat.m32 = 0.0F;
        reflectionMat.m33 = 1.0F;

        return reflectionMat;
    }

    static float Sgn(float a) {
        if (a > 0.0F) {
            return 1.0F;
        }
        if (a < 0.0F) {
            return -1.0F;
        }
        return 0.0F;
    }

    Vector4 CameraSpacePlane(Camera cam, Vector3 pos, Vector3 normal, float sideSign) {
        Vector3 offsetPos = pos + normal * _clipPlaneOffset;
        Matrix4x4 m = cam.worldToCameraMatrix;
        Vector3 cpos = m.MultiplyPoint(offsetPos);
        Vector3 cnormal = m.MultiplyVector(normal).normalized * sideSign;

        return new Vector4(cnormal.x, cnormal.y, cnormal.z, -Vector3.Dot(cpos, cnormal));
    }

    private Dictionary<Camera, CommandBuffer> _cameras = new Dictionary<Camera, CommandBuffer>();

    void PostProcessTexture(Camera cam, RenderTexture source, RenderTexture dest)
    {
      
#if UNITY_EDITOR
        if (_blurParamChanged)
        {
            if (_cameras.ContainsKey(cam))
                cam.RemoveCommandBuffer(CameraEvent.BeforeForwardOpaque, _cameras[cam]);
            _cameras.Remove(cam);
        }
#endif
       
        if (_cameras.ContainsKey(cam))
            return;

        CommandBuffer buf = new CommandBuffer();
        buf.name = "Blur Reflection Texture";
        _cameras[cam] = buf; 
        float width = source.width;
        float height = source.height;
        int rtW = Mathf.RoundToInt(width / _downsample);
        int rtH = Mathf.RoundToInt(height / _downsample);

        int blurredID = Shader.PropertyToID("_Temp1");
        int blurredID2 = Shader.PropertyToID("_Temp2");
        buf.GetTemporaryRT(blurredID, rtW, rtH, 0, FilterMode.Bilinear, source.format);
        buf.GetTemporaryRT(blurredID2, rtW, rtH, 0, FilterMode.Bilinear, source.format);

        buf.Blit((Texture)source, blurredID);
        for (int i = 0; i < _blurIterations; i++)
        {
            float iterationOffs = (i * 1.0f);
            buf.SetGlobalFloat("_Offset", iterationOffs / _downsample + _blurSize);
            buf.Blit(blurredID, blurredID2, BlurMaterial, 0);
            buf.Blit(blurredID2, blurredID, BlurMaterial, 0);
        }
        buf.Blit(blurredID, dest);

        buf.ReleaseTemporaryRT(blurredID);
        buf.ReleaseTemporaryRT(blurredID2);

        cam.AddCommandBuffer(CameraEvent.BeforeForwardOpaque, buf);
    }

}
```

<!-- endtab -->

<!-- tab 运镜工具-->

```
using System.Collections.Generic;  
using UnityEngine;  
  
public class CameraMovement : MonoBehaviour  
{  
    public List<Transform> pathPoints;  
    public float moveSpeed = 2.0f;  
    public float rotationSpeed = 30.0f;  
    private int currentIndex = 0;  
    private Transform target;  
    private bool isMoving = false;  
  
    private void Start()  
    {  
        if (pathPoints != null && pathPoints.Count > 0)  
        {  
            target = pathPoints[currentIndex];  
        }  
    }  
  
    private void Update()  
    {  
        // 检查是否按下空格键来启动或停止相机运动  
        if (Input.GetKeyDown(KeyCode.Space))  
        {  
            isMoving = !isMoving;  
        }  
  
        if (!isMoving || target == null) return;  
  
        Vector3 directionToTarget = (target.position - transform.position).normalized;  
        transform.Translate(directionToTarget * moveSpeed * Time.deltaTime, Space.World);  
  
        if (Vector3.Distance(transform.position, target.position) < 0.1f)  
        {  
            currentIndex = (currentIndex + 1) % pathPoints.Count;  
            target = pathPoints[currentIndex];  
  
            Quaternion targetRotation = Quaternion.LookRotation(target.position - transform.position);  
            transform.rotation = Quaternion.RotateTowards(transform.rotation, targetRotation, rotationSpeed * Time.deltaTime);  
        }  
    }  
}
```

<!-- endtab -->

{% endtabs %}
